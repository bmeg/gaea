remember to set up the auto-timeouts!
also, btw, every time you create a kafka consumer, you are creating a thread that doesn't exit until you close that consumer down
(I discovered this in profiling peregrine)
this isn't a HUGE deal - they are threads with very short stack traces, so they don't use much memory, and they just sit there doing nothing (the OS only wakes them up when they have data to read) so they are not wasting cpu, just a bit of memory
but you know, it's nicer not to have hundreds of little garbage threads around

Are you using a zookeeper cluster and a kafka cluster yet?

yes

So what, three zookeeper machines and three kafka machines?

the clusters have been great - but watch out for zookeeper logs!
zookeeper can run out of disk space for logs fast, and you need to rotate them out to s3 or /dev/null by hand
three machines, each holds a zk and a kafka
and the issue with the zk logs is that once you have a cluster, there's a LOT more log activity
and the logs fill up the disk etc. etc.
also, remember when we turned off the "64 connections from one host at a time" limit in zk?
that limit being hit was exposing the thread leak bug
the fact that the threads reading from kafka were never exiting, despite being done
I blame the kafka API which simply hands you a "consumer" and doesn't tell you it contains a thread that doesn't exit until the consumer is gone (we were putting the consumer in a core.async go block, so it never disappeared)
so I recommend never changing the 64 connections per host limit - and if you hit 64 connections from one host, fix the real problem (the fact that consumer garbage is building up)
and yeah, the kafka / zookeeper setup thing is one of many blog posts I could, and should, write
also, I discovered that you can do coordination via the kafka API instead of directly using zookeeper, since the messages are immutably and strongly ordered, you can have an algo that does a multi-part claim - the first consumer to complete the multi-step claim process uninterrupted by other overlapping claims wins
I haven't done it yet, but it seems elegant if done right
so it would look like send("I nominate me! <UID>"); send("Any objections?") followed by reading the stream you just sent too, and verifying no other nominations happened in between your nomination and your second message
